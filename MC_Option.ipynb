{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "D5ncQuHgFqFT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6c1ca70-1090-476e-dbe7-d0e72d586ebb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cupy\n",
        "import numpy as np\n",
        "import math\n",
        "import time\n",
        "import numba\n",
        "from numba import cuda\n",
        "from numba import njit\n",
        "from numba import prange\n",
        "import cudf\n",
        "cupy.cuda.set_allocator(None)\n",
        "\n",
        "N_PATHS = 16192000\n",
        "N_STEPS = 365\n",
        "T = 1.0\n",
        "K = 110.0\n",
        "B = 100.0\n",
        "S0 = 120.0\n",
        "sigma = 0.35\n",
        "mu = 0.1\n",
        "r = 0.05"
      ],
      "metadata": {
        "id": "xUvPMJZ5POTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Single Thread CPU"
      ],
      "metadata": {
        "id": "PIhZIgLwO7Mj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@njit(fastmath=True)\n",
        "def cpu_barrier_option(d_s, T, K, B, S0, sigma, mu, r, d_normals, N_STEPS, N_PATHS):\n",
        "    tmp1 = mu*T/N_STEPS\n",
        "    tmp2 = math.exp(-r*T)\n",
        "    tmp3 = math.sqrt(T/N_STEPS)\n",
        "    running_average = 0.0\n",
        "    for i in range(N_PATHS):\n",
        "        s_curr = S0\n",
        "        for n in range(N_STEPS):\n",
        "            s_curr += tmp1 * s_curr + sigma*s_curr*tmp3*d_normals[i + n * N_PATHS]\n",
        "            running_average = running_average + 1.0/(n + 1.0) * (s_curr - running_average)\n",
        "            if running_average <= B:\n",
        "                break\n",
        "\n",
        "        payoff = running_average - K if running_average>K else 0\n",
        "        d_s[i] = tmp2 * payoff"
      ],
      "metadata": {
        "id": "3423v90tQB_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "randoms_gpu = cupy.random.normal(0, 1, N_PATHS * N_STEPS, dtype=cupy.float32)\n",
        "randoms_cpu = np_randoms = cupy.asnumpy(randoms_gpu)\n",
        "output =  np.zeros(N_PATHS, dtype=np.float32)\n",
        "\n",
        "cpu_barrier_option(output, np.float32(T), np.float32(K),\n",
        "                    np.float32(B), np.float32(S0),\n",
        "                    np.float32(sigma), np.float32(mu),\n",
        "                    np.float32(r), randoms_cpu, N_STEPS, N_PATHS)\n",
        "s = time.time()\n",
        "cpu_barrier_option(output, np.float32(T), np.float32(K),\n",
        "                    np.float32(B), np.float32(S0),\n",
        "                    np.float32(sigma), np.float32(mu),\n",
        "                    np.float32(r), randoms_cpu, N_STEPS, N_PATHS)\n",
        "v = output.mean()\n",
        "e = time.time()\n",
        "print('time', e-s, 'v', v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tXfkBkEO8Nj",
        "outputId": "52a20916-2b69-4733-96ca-e0f32ce2b9ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time 10.073435068130493 v 18.709488\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cupy as cp\n",
        "\n",
        "# Calculate batch size (adjust target_mb_per_batch if needed)\n",
        "elements_per_mb = 262144\n",
        "target_mb_per_batch = 150\n",
        "BATCH_SIZE = (target_mb_per_batch * elements_per_mb) // N_STEPS\n",
        "BATCH_SIZE = min(BATCH_SIZE, 100000)  # Cap at 100k paths per batch\n",
        "\n",
        "print(f\"Processing with batch size: {BATCH_SIZE} paths\")\n",
        "output = np.zeros(N_PATHS, dtype=np.float32)\n",
        "\n",
        "# Start timing for the whole computation\n",
        "total_start = time.time()\n",
        "\n",
        "running_sum = 0.0\n",
        "processed_paths = 0\n",
        "\n",
        "for i in range(0, N_PATHS, BATCH_SIZE):\n",
        "    end_idx = min(i + BATCH_SIZE, N_PATHS)\n",
        "    batch_size = end_idx - i\n",
        "\n",
        "    # Generate random numbers for this batch\n",
        "    randoms_gpu = cp.random.normal(0, 1, batch_size * N_STEPS, dtype=cp.float32)\n",
        "    randoms_cpu = cp.asnumpy(randoms_gpu)\n",
        "\n",
        "    # Process batch\n",
        "    batch_output = np.zeros(batch_size, dtype=np.float32)\n",
        "\n",
        "    s = time.time()\n",
        "    cpu_barrier_option(batch_output, np.float32(T), np.float32(K),\n",
        "                      np.float32(B), np.float32(S0),\n",
        "                      np.float32(sigma), np.float32(mu),\n",
        "                      np.float32(r), randoms_cpu, N_STEPS, batch_size)\n",
        "\n",
        "    # Store results and update running statistics\n",
        "    output[i:end_idx] = batch_output\n",
        "    running_sum += np.sum(batch_output)\n",
        "    processed_paths += batch_size\n",
        "\n",
        "    # Clean up GPU memory\n",
        "    del randoms_gpu\n",
        "    cp.get_default_memory_pool().free_all_blocks()\n",
        "\n",
        "    # Print progress every 10 batches\n",
        "    if (i // BATCH_SIZE) % 10 == 0:\n",
        "        current_mean = running_sum / processed_paths\n",
        "        print(f\"Processed {processed_paths:,}/{N_PATHS:,} paths ({processed_paths/N_PATHS*100:.1f}%)\")\n",
        "        print(f\"Current running mean: {current_mean:.6f}\")\n",
        "\n",
        "# Calculate final mean\n",
        "final_mean = running_sum / N_PATHS\n",
        "total_time = time.time() - total_start\n",
        "\n",
        "print('='*50)\n",
        "print(f'Total time: {total_time:.2f} seconds')\n",
        "print(f'Final value: {final_mean:.6f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwDWLTbzTH7U",
        "outputId": "f3c01299-8c9c-4282-8603-7b20b860ef14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing with batch size: 100000 paths\n",
            "Processed 100,000/3,192,000 paths (3.1%)\n",
            "Current running mean: 18.709576\n",
            "Processed 1,100,000/3,192,000 paths (34.5%)\n",
            "Current running mean: 18.730733\n",
            "Processed 2,100,000/3,192,000 paths (65.8%)\n",
            "Current running mean: 18.743807\n",
            "Processed 3,100,000/3,192,000 paths (97.1%)\n",
            "Current running mean: 18.744738\n",
            "==================================================\n",
            "Total time: 11.47 seconds\n",
            "Final value: 18.741956\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multiple Cores CPU"
      ],
      "metadata": {
        "id": "UrpQ936lSjpf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@njit(fastmath=True, parallel=True)\n",
        "def cpu_multiplecore_barrier_option(d_s, T, K, B, S0, sigma, mu, r, d_normals, N_STEPS, N_PATHS):\n",
        "    tmp1 = mu*T/N_STEPS\n",
        "    tmp2 = math.exp(-r*T)\n",
        "    tmp3 = math.sqrt(T/N_STEPS)\n",
        "\n",
        "    # Pre-calculate 1/(n+1) values\n",
        "    inv_n = np.array([1.0/(n + 1.0) for n in range(N_STEPS)])\n",
        "\n",
        "    for i in prange(N_PATHS):\n",
        "        s_curr = S0\n",
        "        s_values = np.zeros(N_STEPS)\n",
        "        barrier_hit = False\n",
        "\n",
        "        # First pass: calculate all stock prices\n",
        "        for n in range(N_STEPS):\n",
        "            s_curr += tmp1 * s_curr + sigma*s_curr*tmp3*d_normals[n + i * N_STEPS]\n",
        "            s_values[n] = s_curr\n",
        "\n",
        "        # Second pass: calculate running average\n",
        "        running_average = 0.0\n",
        "        for n in range(N_STEPS):\n",
        "            running_average = running_average + inv_n[n] * (s_values[n] - running_average)\n",
        "            if running_average <= B:\n",
        "                barrier_hit = True\n",
        "                break\n",
        "\n",
        "        payoff = running_average - K if (running_average > K and not barrier_hit) else 0\n",
        "        d_s[i] = tmp2 * payoff"
      ],
      "metadata": {
        "id": "vFekRr33Tc9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "randoms_gpu = cupy.random.normal(0, 1, N_PATHS * N_STEPS, dtype=cupy.float32)\n",
        "randoms_cpu = np_randoms = cupy.asnumpy(randoms_gpu)\n",
        "output =  np.zeros(N_PATHS, dtype=np.float32)\n",
        "cpu_multiplecore_barrier_option(output, np.float32(T), np.float32(K),\n",
        "                    np.float32(B), np.float32(S0),\n",
        "                    np.float32(sigma), np.float32(mu),\n",
        "                    np.float32(r), randoms_cpu, N_STEPS, N_PATHS)\n",
        "s = time.time()\n",
        "cpu_multiplecore_barrier_option(output, np.float32(T), np.float32(K),\n",
        "                    np.float32(B), np.float32(S0),\n",
        "                    np.float32(sigma), np.float32(mu),\n",
        "                    np.float32(r), randoms_cpu, N_STEPS, N_PATHS)\n",
        "v = output.mean()\n",
        "e = time.time()\n",
        "print('time', e-s, 'v', v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OB3q0DIMPvDP",
        "outputId": "ddde9cb9-4089-4fc4-ec26-3335d1ce853e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time 3.929661273956299 v 18.728195\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate batch size\n",
        "import cupy as cp\n",
        "elements_per_mb = 262144\n",
        "target_mb_per_batch = 150\n",
        "BATCH_SIZE = (target_mb_per_batch * elements_per_mb) // N_STEPS\n",
        "BATCH_SIZE = min(BATCH_SIZE, 100000)\n",
        "\n",
        "print(f\"Processing with batch size: {BATCH_SIZE} paths\")\n",
        "output = np.zeros(N_PATHS, dtype=np.float32)\n",
        "\n",
        "# Compile the function (first call will compile)\n",
        "small_test_size = 1000\n",
        "test_output = np.zeros(small_test_size, dtype=np.float32)\n",
        "test_randoms = np.random.normal(0, 1, small_test_size * N_STEPS).astype(np.float32)\n",
        "cpu_multiplecore_barrier_option(test_output, np.float32(1.0), np.float32(100),\n",
        "                          np.float32(120), np.float32(100),\n",
        "                          np.float32(0.2), np.float32(0.05),\n",
        "                          np.float32(0.05), test_randoms, N_STEPS, small_test_size)\n",
        "\n",
        "# Start timing\n",
        "total_start = time.time()\n",
        "running_sum = 0.0\n",
        "processed_paths = 0\n",
        "\n",
        "for i in range(0, N_PATHS, BATCH_SIZE):\n",
        "    end_idx = min(i + BATCH_SIZE, N_PATHS)\n",
        "    batch_size = end_idx - i\n",
        "\n",
        "    # Generate random numbers for this batch\n",
        "    randoms_gpu = cp.random.normal(0, 1, batch_size * N_STEPS, dtype=cp.float32)\n",
        "    randoms_cpu = cp.asnumpy(randoms_gpu)\n",
        "\n",
        "    # Process batch\n",
        "    batch_output = np.zeros(batch_size, dtype=np.float32)\n",
        "\n",
        "    s = time.time()\n",
        "    cpu_multiplecore_barrier_option(batch_output, np.float32(T), np.float32(K),\n",
        "                              np.float32(B), np.float32(S0),\n",
        "                              np.float32(sigma), np.float32(mu),\n",
        "                              np.float32(r), randoms_cpu, N_STEPS, batch_size)\n",
        "\n",
        "    # Update results and statistics\n",
        "    output[i:end_idx] = batch_output\n",
        "    running_sum += np.sum(batch_output)\n",
        "    processed_paths += batch_size\n",
        "\n",
        "    # Clean up GPU memory\n",
        "    del randoms_gpu\n",
        "    cp.get_default_memory_pool().free_all_blocks()\n",
        "\n",
        "    # Print progress\n",
        "    if (i // BATCH_SIZE) % 10 == 0:\n",
        "        current_mean = running_sum / processed_paths\n",
        "        elapsed = time.time() - total_start\n",
        "        paths_per_second = processed_paths / elapsed\n",
        "        print(f\"Processed {processed_paths:,}/{N_PATHS:,} paths ({processed_paths/N_PATHS*100:.1f}%)\")\n",
        "        print(f\"Current mean: {current_mean:.6f}\")\n",
        "        print(f\"Processing speed: {paths_per_second:.0f} paths/second\")\n",
        "\n",
        "final_mean = running_sum / N_PATHS\n",
        "total_time = time.time() - total_start\n",
        "\n",
        "print('='*50)\n",
        "print(f'Total time: {total_time:.2f} seconds')\n",
        "print(f'Final value: {final_mean:.6f}')\n",
        "print(f'Average processing speed: {N_PATHS/total_time:.0f} paths/second')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AQpmNnrUebs",
        "outputId": "5741f419-b13d-4a87-e750-414cd6a7e08e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing with batch size: 100000 paths\n",
            "Processed 100,000/3,192,000 paths (3.1%)\n",
            "Current mean: 18.708804\n",
            "Processing speed: 607406 paths/second\n",
            "Processed 1,100,000/3,192,000 paths (34.5%)\n",
            "Current mean: 18.693948\n",
            "Processing speed: 575533 paths/second\n",
            "Processed 2,100,000/3,192,000 paths (65.8%)\n",
            "Current mean: 18.718199\n",
            "Processing speed: 551608 paths/second\n",
            "Processed 3,100,000/3,192,000 paths (97.1%)\n",
            "Current mean: 18.716147\n",
            "Processing speed: 575150 paths/second\n",
            "==================================================\n",
            "Total time: 5.53 seconds\n",
            "Final value: 18.716864\n",
            "Average processing speed: 576910 paths/second\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NUMBA GPU"
      ],
      "metadata": {
        "id": "l7H4aXOcSnZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@cuda.jit\n",
        "def numba_barrier_option(d_s, T, K, B, S0, sigma, mu, r, d_normals, N_STEPS, N_PATHS):  # Make sure all parameters are here\n",
        "    # Get thread ID\n",
        "    tid = cuda.grid(1)  # 1D grid\n",
        "\n",
        "    # Check if thread is within bounds\n",
        "    if tid < N_PATHS:\n",
        "        s_curr = S0\n",
        "        running_average = 0.0\n",
        "        for n in range(N_STEPS):\n",
        "            s_curr += mu*T/N_STEPS * s_curr + sigma*s_curr*math.sqrt(T/N_STEPS)*d_normals[tid + n * N_PATHS]\n",
        "            running_average = running_average + 1.0/(n + 1.0) * (s_curr - running_average)\n",
        "            if running_average <= B:\n",
        "                break\n",
        "        payoff = running_average - K if running_average > K else 0\n",
        "        d_s[tid] = math.exp(-r*T) * payoff"
      ],
      "metadata": {
        "id": "ultHTkPEU4pW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "randoms_gpu = cupy.random.normal(0, 1, N_PATHS * N_STEPS, dtype=cupy.float32)\n",
        "randoms_cpu = np_randoms = cupy.asnumpy(randoms_gpu)\n",
        "output =  np.zeros(N_PATHS, dtype=np.float32)\n",
        "number_of_threads = 256\n",
        "number_of_blocks = (N_PATHS-1) // number_of_threads + 1\n",
        "output = cupy.zeros(N_PATHS, dtype=cupy.float32)\n",
        "numba_barrier_option[(number_of_blocks,), (number_of_threads,)](output, np.float32(T), np.float32(K),\n",
        "                    np.float32(B), np.float32(S0),\n",
        "                    np.float32(sigma), np.float32(mu),\n",
        "                    np.float32(r), randoms_gpu, N_STEPS, N_PATHS)\n",
        "s = time.time()\n",
        "numba_barrier_option[(number_of_blocks,), (number_of_threads,)](output, np.float32(T), np.float32(K),\n",
        "                    np.float32(B), np.float32(S0),\n",
        "                    np.float32(sigma), np.float32(mu),\n",
        "                    np.float32(r), randoms_gpu, N_STEPS, N_PATHS)\n",
        "v = output.mean()\n",
        "cuda.synchronize()\n",
        "e = time.time()\n",
        "print('time', e-s, 'v', v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlJiRr_pQn7B",
        "outputId": "75f78662-e05a-44ac-e4ef-22ad874c6370"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time 0.48715853691101074 v 18.705944\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate batch size\n",
        "import cupy as cp\n",
        "number_of_threads = 256\n",
        "number_of_blocks = (N_PATHS-1) // number_of_threads + 1\n",
        "elements_per_mb = 262144\n",
        "target_mb_per_batch = 150\n",
        "BATCH_SIZE = (target_mb_per_batch * elements_per_mb) // N_STEPS\n",
        "BATCH_SIZE = min(BATCH_SIZE, 100000)\n",
        "\n",
        "print(f\"Processing with batch size: {BATCH_SIZE} paths\")\n",
        "output = np.zeros(N_PATHS, dtype=np.float32)\n",
        "\n",
        "# Compile the function (first call will compile)\n",
        "small_test_size = 1000\n",
        "test_output = np.zeros(small_test_size, dtype=np.float32)\n",
        "test_randoms = np.random.normal(0, 1, small_test_size * N_STEPS).astype(np.float32)\n",
        "numba_barrier_option[(number_of_blocks,), (number_of_threads,)](test_output, np.float32(1.0), np.float32(100),\n",
        "                          np.float32(120), np.float32(100),\n",
        "                          np.float32(0.2), np.float32(0.05),\n",
        "                          np.float32(0.05), test_randoms, N_STEPS, small_test_size)\n",
        "\n",
        "# Start timing\n",
        "total_start = time.time()\n",
        "running_sum = 0.0\n",
        "processed_paths = 0\n",
        "\n",
        "for i in range(0, N_PATHS, BATCH_SIZE):\n",
        "    end_idx = min(i + BATCH_SIZE, N_PATHS)\n",
        "    batch_size = end_idx - i\n",
        "\n",
        "    # Generate random numbers for this batch\n",
        "    randoms_gpu = cp.random.normal(0, 1, batch_size * N_STEPS, dtype=cp.float32)\n",
        "    randoms_cpu = cp.asnumpy(randoms_gpu)\n",
        "\n",
        "    # Process batch\n",
        "    batch_output = np.zeros(batch_size, dtype=np.float32)\n",
        "\n",
        "    s = time.time()\n",
        "    numba_barrier_option[(number_of_blocks,), (number_of_threads,)](batch_output, np.float32(T), np.float32(K),\n",
        "                              np.float32(B), np.float32(S0),\n",
        "                              np.float32(sigma), np.float32(mu),\n",
        "                              np.float32(r), randoms_cpu, N_STEPS, batch_size)\n",
        "\n",
        "    # Update results and statistics\n",
        "    output[i:end_idx] = batch_output\n",
        "    running_sum += np.sum(batch_output)\n",
        "    processed_paths += batch_size\n",
        "\n",
        "    # Clean up GPU memory\n",
        "    del randoms_gpu\n",
        "    cp.get_default_memory_pool().free_all_blocks()\n",
        "\n",
        "    # Print progress\n",
        "    if (i // BATCH_SIZE) % 10 == 0:\n",
        "        current_mean = running_sum / processed_paths\n",
        "        elapsed = time.time() - total_start\n",
        "        paths_per_second = processed_paths / elapsed\n",
        "        print(f\"Processed {processed_paths:,}/{N_PATHS:,} paths ({processed_paths/N_PATHS*100:.1f}%)\")\n",
        "        print(f\"Current mean: {current_mean:.6f}\")\n",
        "        print(f\"Processing speed: {paths_per_second:.0f} paths/second\")\n",
        "\n",
        "final_mean = running_sum / N_PATHS\n",
        "total_time = time.time() - total_start\n",
        "\n",
        "print('='*50)\n",
        "print(f'Total time: {total_time:.2f} seconds')\n",
        "print(f'Final value: {final_mean:.6f}')\n",
        "print(f'Average processing speed: {N_PATHS/total_time:.0f} paths/second')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Til4ITTsEvLG",
        "outputId": "8c313e0e-aa9c-4697-a3a7-f5ea88f1dc7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing with batch size: 100000 paths\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: Host array used in CUDA kernel will incur copy overhead to/from device.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 100,000/3,192,000 paths (3.1%)\n",
            "Current mean: 18.592958\n",
            "Processing speed: 687307 paths/second\n",
            "Processed 1,100,000/3,192,000 paths (34.5%)\n",
            "Current mean: 18.699063\n",
            "Processing speed: 705193 paths/second\n",
            "Processed 2,100,000/3,192,000 paths (65.8%)\n",
            "Current mean: 18.703537\n",
            "Processing speed: 716049 paths/second\n",
            "Processed 3,100,000/3,192,000 paths (97.1%)\n",
            "Current mean: 18.702760\n",
            "Processing speed: 722328 paths/second\n",
            "==================================================\n",
            "Total time: 4.41 seconds\n",
            "Final value: 18.700663\n",
            "Average processing speed: 723021 paths/second\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CUPY GPU"
      ],
      "metadata": {
        "id": "mCOIZ2fQSq7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cupy_barrier_option = cupy.RawKernel(r'''\n",
        "extern \"C\" __global__ void barrier_option(\n",
        "    float *d_s,\n",
        "    const float T,\n",
        "    const float K,\n",
        "    const float B,\n",
        "    const float S0,\n",
        "    const float sigma,\n",
        "    const float mu,\n",
        "    const float r,\n",
        "    const float * d_normals,\n",
        "    const long N_STEPS,\n",
        "    const long N_PATHS)\n",
        "{\n",
        "    unsigned idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    unsigned stride = blockDim.x * gridDim.x;\n",
        "\n",
        "    // Precompute constants\n",
        "    const float tmp1 = mu * T / N_STEPS;\n",
        "    const float tmp2 = exp(-r * T);\n",
        "    const float tmp3 = sqrt(T / N_STEPS);\n",
        "\n",
        "    // Use shared memory for frequently accessed data\n",
        "    __shared__ float s_temp[32];  // Adjust size based on your block size\n",
        "\n",
        "    for (unsigned i = idx; i < N_PATHS; i += stride) {\n",
        "        float s_curr = S0;\n",
        "        float running_average = 0.0f;  // Changed to float for consistency\n",
        "\n",
        "        // Reorganized memory access pattern\n",
        "        const unsigned base_idx = i * N_STEPS;\n",
        "\n",
        "        for(unsigned n = 0; n < N_STEPS; n++) {\n",
        "            s_curr += tmp1 * s_curr + sigma * s_curr * tmp3 * d_normals[base_idx + n];\n",
        "            running_average += (s_curr - running_average) / (n + 1.0f);\n",
        "\n",
        "            if (running_average <= B) {\n",
        "                break;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        float payoff = (running_average > K) ? (running_average - K) : 0.0f;\n",
        "        d_s[i] = tmp2 * payoff;\n",
        "    }\n",
        "}\n",
        "''', 'barrier_option')"
      ],
      "metadata": {
        "id": "7qXv84AdE09d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "randoms_gpu = cupy.random.normal(0, 1, N_PATHS * N_STEPS, dtype=cupy.float32)\n",
        "randoms_cpu = np_randoms = cupy.asnumpy(randoms_gpu)\n",
        "output = cupy.zeros(N_PATHS, dtype=cupy.float32)\n",
        "number_of_threads = 256\n",
        "number_of_blocks = (N_PATHS-1) // number_of_threads + 1\n",
        "s = time.time()\n",
        "cupy_barrier_option((number_of_blocks,), (number_of_threads,),\n",
        "                   (output, np.float32(T), np.float32(K),\n",
        "                    np.float32(B), np.float32(S0),\n",
        "                    np.float32(sigma), np.float32(mu),\n",
        "                    np.float32(r),  randoms_gpu, N_STEPS, N_PATHS))\n",
        "v = output.mean()\n",
        "cupy.cuda.stream.get_current_stream().synchronize()\n",
        "e = time.time()\n",
        "print('time', e-s, 'v',v)"
      ],
      "metadata": {
        "id": "L1IX4LiIReIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cupy as cp\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "# Calculate batch size\n",
        "number_of_threads = 256\n",
        "number_of_blocks = (N_PATHS-1) // number_of_threads + 1\n",
        "output = cp.zeros(N_PATHS, dtype=cp.float32)\n",
        "elements_per_mb = 262144\n",
        "target_mb_per_batch = 150\n",
        "BATCH_SIZE = (target_mb_per_batch * elements_per_mb) // N_STEPS\n",
        "BATCH_SIZE = min(BATCH_SIZE, 100000)\n",
        "\n",
        "print(f\"Processing with batch size: {BATCH_SIZE} paths\")\n",
        "\n",
        "# Compile the function (first call will compile)\n",
        "small_test_size = 1000\n",
        "test_output = cp.zeros(small_test_size, dtype=cp.float32)\n",
        "test_randoms = cp.random.normal(0, 1, small_test_size * N_STEPS, dtype=cp.float32)\n",
        "\n",
        "# Test kernel launch\n",
        "number_of_blocks_test = (small_test_size + number_of_threads - 1) // number_of_threads\n",
        "cupy_barrier_option((number_of_blocks_test,), (number_of_threads,),(\n",
        "    test_output,\n",
        "    np.float32(1.0),\n",
        "    np.float32(100),\n",
        "    np.float32(120),\n",
        "    np.float32(100),\n",
        "    np.float32(0.2),\n",
        "    np.float32(0.05),\n",
        "    np.float32(0.05),\n",
        "    test_randoms,\n",
        "    N_STEPS,\n",
        "    small_test_size\n",
        "))\n",
        "\n",
        "# Start timing\n",
        "total_start = time.time()\n",
        "running_sum = 0.0\n",
        "processed_paths = 0\n",
        "\n",
        "for i in range(0, N_PATHS, BATCH_SIZE):\n",
        "    end_idx = min(i + BATCH_SIZE, N_PATHS)\n",
        "    batch_size = end_idx - i\n",
        "\n",
        "    # Calculate blocks for this batch\n",
        "    blocks_for_batch = (batch_size + number_of_threads - 1) // number_of_threads\n",
        "\n",
        "    # Generate random numbers directly on GPU\n",
        "    randoms_gpu = cp.random.normal(0, 1, batch_size * N_STEPS, dtype=cp.float32)\n",
        "\n",
        "    # Allocate output on GPU\n",
        "    batch_output_gpu = cp.zeros(batch_size, dtype=cp.float32)\n",
        "\n",
        "    s = time.time()\n",
        "    cupy_barrier_option((blocks_for_batch,), (number_of_threads,),(\n",
        "        batch_output_gpu,\n",
        "        np.float32(T),\n",
        "        np.float32(K),\n",
        "        np.float32(B),\n",
        "        np.float32(S0),\n",
        "        np.float32(sigma),\n",
        "        np.float32(mu),\n",
        "        np.float32(r),\n",
        "        randoms_gpu,\n",
        "        N_STEPS,\n",
        "        batch_size\n",
        "    ))\n",
        "\n",
        "    # Copy results back to CPU only if needed for statistics\n",
        "    batch_output = cp.asnumpy(batch_output_gpu)\n",
        "\n",
        "    # Update results and statistics\n",
        "    output[i:end_idx] = batch_output_gpu\n",
        "    running_sum += float(cp.sum(batch_output_gpu))  # Convert CuPy sum to Python float\n",
        "    processed_paths += batch_size\n",
        "\n",
        "    # Clean up GPU memory\n",
        "    del randoms_gpu\n",
        "    del batch_output_gpu\n",
        "    cp.get_default_memory_pool().free_all_blocks()\n",
        "\n",
        "    # Print progress\n",
        "    if (i // BATCH_SIZE) % 10 == 0:\n",
        "        current_mean = running_sum / processed_paths\n",
        "        elapsed = time.time() - total_start\n",
        "        paths_per_second = processed_paths / elapsed\n",
        "        # print(f\"Processed {processed_paths:,}/{N_PATHS:,} paths ({processed_paths/N_PATHS*100:.1f}%)\")\n",
        "        # print(f\"Current mean: {current_mean:.6f}\")\n",
        "        # print(f\"Processing speed: {paths_per_second:.0f} paths/second\")\n",
        "\n",
        "final_mean = running_sum / N_PATHS\n",
        "total_time = time.time() - total_start\n",
        "\n",
        "print('='*50)\n",
        "print(f'Total time: {total_time:.2f} seconds')\n",
        "print(f'Final value: {final_mean:.6f}')\n",
        "print(f'Average processing speed: {N_PATHS/total_time:.0f} paths/second')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUGnQ-dAHzzH",
        "outputId": "53a69c46-6c2d-403c-e64a-1ded57ddc0d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing with batch size: 100000 paths\n",
            "==================================================\n",
            "Total time: 1.82 seconds\n",
            "Final value: 18.709442\n",
            "Average processing speed: 8920861 paths/second\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4bcLGeDZU667"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}